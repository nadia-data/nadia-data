{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"On utilise le corpus \"brown\" un corpus Anglais","metadata":{}},{"cell_type":"code","source":"import nltk","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:39:54.668006Z","iopub.execute_input":"2021-06-25T14:39:54.668666Z","iopub.status.idle":"2021-06-25T14:39:56.103447Z","shell.execute_reply.started":"2021-06-25T14:39:54.668579Z","shell.execute_reply":"2021-06-25T14:39:56.102409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tokenization","metadata":{}},{"cell_type":"code","source":"nltk.download('webtext')\nfrom nltk.corpus import webtext","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:39:56.105141Z","iopub.execute_input":"2021-06-25T14:39:56.105531Z","iopub.status.idle":"2021-06-25T14:40:16.147069Z","shell.execute_reply.started":"2021-06-25T14:39:56.105488Z","shell.execute_reply":"2021-06-25T14:40:16.146066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"webtext.fileids() # fileids c'est le nombre de fichier","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:16.148681Z","iopub.execute_input":"2021-06-25T14:40:16.148949Z","iopub.status.idle":"2021-06-25T14:40:16.161475Z","shell.execute_reply.started":"2021-06-25T14:40:16.148923Z","shell.execute_reply":"2021-06-25T14:40:16.160391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Webtext contient 5 fichiers","metadata":{}},{"cell_type":"code","source":"webtext.sents(fileids='firefox.txt')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:16.163094Z","iopub.execute_input":"2021-06-25T14:40:16.163462Z","iopub.status.idle":"2021-06-25T14:40:16.471156Z","shell.execute_reply.started":"2021-06-25T14:40:16.163433Z","shell.execute_reply":"2021-06-25T14:40:16.470243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(webtext.sents(fileids='firefox.txt'))","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:16.472302Z","iopub.execute_input":"2021-06-25T14:40:16.472574Z","iopub.status.idle":"2021-06-25T14:40:16.765722Z","shell.execute_reply.started":"2021-06-25T14:40:16.472547Z","shell.execute_reply":"2021-06-25T14:40:16.764951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk import sent_tokenize\nsingle_no9 = webtext.raw('singles.txt').split('\\n')[9]\nsent_tokenize(single_no9)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:16.766841Z","iopub.execute_input":"2021-06-25T14:40:16.767144Z","iopub.status.idle":"2021-06-25T14:40:16.776251Z","shell.execute_reply.started":"2021-06-25T14:40:16.767113Z","shell.execute_reply":"2021-06-25T14:40:16.775009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, line in enumerate (webtext.raw('singles.txt').split('\\n')):\n    print(str(i) + ':\\t' + line)\n    if i>10:\n        break","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:16.777721Z","iopub.execute_input":"2021-06-25T14:40:16.778011Z","iopub.status.idle":"2021-06-25T14:40:16.786569Z","shell.execute_reply.started":"2021-06-25T14:40:16.777985Z","shell.execute_reply":"2021-06-25T14:40:16.785576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentence=webtext.raw('singles.txt').split('\\n')[8]\nsentence","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:16.788971Z","iopub.execute_input":"2021-06-25T14:40:16.78925Z","iopub.status.idle":"2021-06-25T14:40:16.795263Z","shell.execute_reply.started":"2021-06-25T14:40:16.789224Z","shell.execute_reply":"2021-06-25T14:40:16.794367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sentence Tokenization","metadata":{}},{"cell_type":"code","source":"from nltk import sent_tokenize\nsent_tokenize(sentence)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:16.796776Z","iopub.execute_input":"2021-06-25T14:40:16.797062Z","iopub.status.idle":"2021-06-25T14:40:16.807193Z","shell.execute_reply.started":"2021-06-25T14:40:16.797012Z","shell.execute_reply":"2021-06-25T14:40:16.806294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Word Tokenization","metadata":{}},{"cell_type":"code","source":"from nltk import word_tokenize\nWords=[]\nfor sent in sent_tokenize(sentence):\n    Words.append(word_tokenize(sent))\nWords","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:16.808353Z","iopub.execute_input":"2021-06-25T14:40:16.808601Z","iopub.status.idle":"2021-06-25T14:40:16.819466Z","shell.execute_reply.started":"2021-06-25T14:40:16.808576Z","shell.execute_reply":"2021-06-25T14:40:16.81874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lowercasing\n","metadata":{}},{"cell_type":"code","source":"for sent in sent_tokenize(sentence):\n    print([word.lower() for word in word_tokenize(sent)])\n    ","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:16.820673Z","iopub.execute_input":"2021-06-25T14:40:16.821268Z","iopub.status.idle":"2021-06-25T14:40:16.831248Z","shell.execute_reply.started":"2021-06-25T14:40:16.821225Z","shell.execute_reply":"2021-06-25T14:40:16.830243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sent_tokenize(sentence)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:16.832555Z","iopub.execute_input":"2021-06-25T14:40:16.832955Z","iopub.status.idle":"2021-06-25T14:40:16.840308Z","shell.execute_reply.started":"2021-06-25T14:40:16.832914Z","shell.execute_reply":"2021-06-25T14:40:16.839557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stopwords","metadata":{}},{"cell_type":"code","source":"from nltk.corpus import stopwords\n\nstopwords_en = stopwords.words('english')\nprint(stopwords_en)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:16.841308Z","iopub.execute_input":"2021-06-25T14:40:16.841758Z","iopub.status.idle":"2021-06-25T14:40:16.86606Z","shell.execute_reply.started":"2021-06-25T14:40:16.84173Z","shell.execute_reply":"2021-06-25T14:40:16.865377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lowering and removing stopwords","metadata":{}},{"cell_type":"code","source":"from nltk.corpus import stopwords\nfrom nltk import word_tokenize\n\nstopwords = stopwords.words('english')\nData=\"This is a sample sentence, showing off the stop words filtration\"\nWords= word_tokenize(Data)\nCleaned_Data=[word for word in Words if word.lower() not in stopwords]\nCleaned_Data","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:16.866982Z","iopub.execute_input":"2021-06-25T14:40:16.867372Z","iopub.status.idle":"2021-06-25T14:40:16.874385Z","shell.execute_reply.started":"2021-06-25T14:40:16.867345Z","shell.execute_reply":"2021-06-25T14:40:16.873668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fonction map : apply the given function to each item of a given iterable ","metadata":{}},{"cell_type":"code","source":"sentence_lowered_tokenized=list(map(str.lower,word_tokenize(single_no9)))\nsentence_lowered_tokenized","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:16.875363Z","iopub.execute_input":"2021-06-25T14:40:16.875801Z","iopub.status.idle":"2021-06-25T14:40:16.887536Z","shell.execute_reply.started":"2021-06-25T14:40:16.875773Z","shell.execute_reply":"2021-06-25T14:40:16.886756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#nltk.download('stopwords')\n#stopwords_en = set(stopwords.words('english')) # Set checking is faster in Python than list.\nprint([word for word in sentence_lowered_tokenized if word not in stopwords_en])","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:16.88868Z","iopub.execute_input":"2021-06-25T14:40:16.889171Z","iopub.status.idle":"2021-06-25T14:40:16.897179Z","shell.execute_reply.started":"2021-06-25T14:40:16.889142Z","shell.execute_reply":"2021-06-25T14:40:16.89638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pandas DataFrame vs Series","metadata":{}},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:16.898304Z","iopub.execute_input":"2021-06-25T14:40:16.898599Z","iopub.status.idle":"2021-06-25T14:40:16.90595Z","shell.execute_reply.started":"2021-06-25T14:40:16.898553Z","shell.execute_reply":"2021-06-25T14:40:16.904994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s = pd.Series(['lower', 'CAPITALS', 'this is a sentence', 'SwApCaSe'])  # serie objet unidimmentionnel\nm= pd.DataFrame(['lower', 'CAPITALS', 'this is a sentence', 'SwApCaSe']) # Dataframe objet bidimensionnel pouvant contenir des s√©ries, des listes et des dictionnaires\ns,m    ","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:16.907274Z","iopub.execute_input":"2021-06-25T14:40:16.907661Z","iopub.status.idle":"2021-06-25T14:40:16.92809Z","shell.execute_reply.started":"2021-06-25T14:40:16.907622Z","shell.execute_reply":"2021-06-25T14:40:16.927411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d = {'one' : pd.Series([1., 2., 3.], index=['a', 'b', 'c']),\n 'two' : pd.Series([1., 2., 3., 4.], index=['a', 'b', 'c', 'd'])}\npd.DataFrame(d)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:16.928968Z","iopub.execute_input":"2021-06-25T14:40:16.92935Z","iopub.status.idle":"2021-06-25T14:40:16.948803Z","shell.execute_reply.started":"2021-06-25T14:40:16.929323Z","shell.execute_reply":"2021-06-25T14:40:16.947993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(s,index=['a', 'b', 'c', 'd'], columns=['fist'])","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:16.949849Z","iopub.execute_input":"2021-06-25T14:40:16.950143Z","iopub.status.idle":"2021-06-25T14:40:16.960342Z","shell.execute_reply.started":"2021-06-25T14:40:16.950117Z","shell.execute_reply":"2021-06-25T14:40:16.959607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s.to_frame(name=\"vals\") # Convert Series to DataFrame","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:16.962716Z","iopub.execute_input":"2021-06-25T14:40:16.962975Z","iopub.status.idle":"2021-06-25T14:40:16.975612Z","shell.execute_reply.started":"2021-06-25T14:40:16.96295Z","shell.execute_reply":"2021-06-25T14:40:16.974819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"set([1,2])","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:16.976711Z","iopub.execute_input":"2021-06-25T14:40:16.977002Z","iopub.status.idle":"2021-06-25T14:40:16.986626Z","shell.execute_reply.started":"2021-06-25T14:40:16.976974Z","shell.execute_reply":"2021-06-25T14:40:16.985542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stopwords-json","metadata":{}},{"cell_type":"code","source":"from string import punctuation\nprint('From string.punctuation:', punctuation)\n# stopwords_json existe dans https://github.com/6/stopwords-json/blob/master/stopwords-all.json\nstopwords_json = {\"en\":[\"a\",\"a's\",\"able\",\"about\",\"above\",\"according\",\"accordingly\",\"across\",\"actually\",\"after\",\"afterwards\",\"again\",\"against\",\"ain't\",\"all\",\"allow\",\"allows\",\"almost\",\"alone\",\"along\",\"already\",\"also\",\"although\",\"always\",\"am\",\"among\",\"amongst\",\"an\",\"and\",\"another\",\"any\",\"anybody\",\"anyhow\",\"anyone\",\"anything\",\"anyway\",\"anyways\",\"anywhere\",\"apart\",\"appear\",\"appreciate\",\"appropriate\",\"are\",\"aren't\",\"around\",\"as\",\"aside\",\"ask\",\"asking\",\"associated\",\"at\",\"available\",\"away\",\"awfully\",\"b\",\"be\",\"became\",\"because\",\"become\",\"becomes\",\"becoming\",\"been\",\"before\",\"beforehand\",\"behind\",\"being\",\"believe\",\"below\",\"beside\",\"besides\",\"best\",\"better\",\"between\",\"beyond\",\"both\",\"brief\",\"but\",\"by\",\"c\",\"c'mon\",\"c's\",\"came\",\"can\",\"can't\",\"cannot\",\"cant\",\"cause\",\"causes\",\"certain\",\"certainly\",\"changes\",\"clearly\",\"co\",\"com\",\"come\",\"comes\",\"concerning\",\"consequently\",\"consider\",\"considering\",\"contain\",\"containing\",\"contains\",\"corresponding\",\"could\",\"couldn't\",\"course\",\"currently\",\"d\",\"definitely\",\"described\",\"despite\",\"did\",\"didn't\",\"different\",\"do\",\"does\",\"doesn't\",\"doing\",\"don't\",\"done\",\"down\",\"downwards\",\"during\",\"e\",\"each\",\"edu\",\"eg\",\"eight\",\"either\",\"else\",\"elsewhere\",\"enough\",\"entirely\",\"especially\",\"et\",\"etc\",\"even\",\"ever\",\"every\",\"everybody\",\"everyone\",\"everything\",\"everywhere\",\"ex\",\"exactly\",\"example\",\"except\",\"f\",\"far\",\"few\",\"fifth\",\"first\",\"five\",\"followed\",\"following\",\"follows\",\"for\",\"former\",\"formerly\",\"forth\",\"four\",\"from\",\"further\",\"furthermore\",\"g\",\"get\",\"gets\",\"getting\",\"given\",\"gives\",\"go\",\"goes\",\"going\",\"gone\",\"got\",\"gotten\",\"greetings\",\"h\",\"had\",\"hadn't\",\"happens\",\"hardly\",\"has\",\"hasn't\",\"have\",\"haven't\",\"having\",\"he\",\"he's\",\"hello\",\"help\",\"hence\",\"her\",\"here\",\"here's\",\"hereafter\",\"hereby\",\"herein\",\"hereupon\",\"hers\",\"herself\",\"hi\",\"him\",\"himself\",\"his\",\"hither\",\"hopefully\",\"how\",\"howbeit\",\"however\",\"i\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\"ie\",\"if\",\"ignored\",\"immediate\",\"in\",\"inasmuch\",\"inc\",\"indeed\",\"indicate\",\"indicated\",\"indicates\",\"inner\",\"insofar\",\"instead\",\"into\",\"inward\",\"is\",\"isn't\",\"it\",\"it'd\",\"it'll\",\"it's\",\"its\",\"itself\",\"j\",\"just\",\"k\",\"keep\",\"keeps\",\"kept\",\"know\",\"known\",\"knows\",\"l\",\"last\",\"lately\",\"later\",\"latter\",\"latterly\",\"least\",\"less\",\"lest\",\"let\",\"let's\",\"like\",\"liked\",\"likely\",\"little\",\"look\",\"looking\",\"looks\",\"ltd\",\"m\",\"mainly\",\"many\",\"may\",\"maybe\",\"me\",\"mean\",\"meanwhile\",\"merely\",\"might\",\"more\",\"moreover\",\"most\",\"mostly\",\"much\",\"must\",\"my\",\"myself\",\"n\",\"name\",\"namely\",\"nd\",\"near\",\"nearly\",\"necessary\",\"need\",\"needs\",\"neither\",\"never\",\"nevertheless\",\"new\",\"next\",\"nine\",\"no\",\"nobody\",\"non\",\"none\",\"noone\",\"nor\",\"normally\",\"not\",\"nothing\",\"novel\",\"now\",\"nowhere\",\"o\",\"obviously\",\"of\",\"off\",\"often\",\"oh\",\"ok\",\"okay\",\"old\",\"on\",\"once\",\"one\",\"ones\",\"only\",\"onto\",\"or\",\"other\",\"others\",\"otherwise\",\"ought\",\"our\",\"ours\",\"ourselves\",\"out\",\"outside\",\"over\",\"overall\",\"own\",\"p\",\"particular\",\"particularly\",\"per\",\"perhaps\",\"placed\",\"please\",\"plus\",\"possible\",\"presumably\",\"probably\",\"provides\",\"q\",\"que\",\"quite\",\"qv\",\"r\",\"rather\",\"rd\",\"re\",\"really\",\"reasonably\",\"regarding\",\"regardless\",\"regards\",\"relatively\",\"respectively\",\"right\",\"s\",\"said\",\"same\",\"saw\",\"say\",\"saying\",\"says\",\"second\",\"secondly\",\"see\",\"seeing\",\"seem\",\"seemed\",\"seeming\",\"seems\",\"seen\",\"self\",\"selves\",\"sensible\",\"sent\",\"serious\",\"seriously\",\"seven\",\"several\",\"shall\",\"she\",\"should\",\"shouldn't\",\"since\",\"six\",\"so\",\"some\",\"somebody\",\"somehow\",\"someone\",\"something\",\"sometime\",\"sometimes\",\"somewhat\",\"somewhere\",\"soon\",\"sorry\",\"specified\",\"specify\",\"specifying\",\"still\",\"sub\",\"such\",\"sup\",\"sure\",\"t\",\"t's\",\"take\",\"taken\",\"tell\",\"tends\",\"th\",\"than\",\"thank\",\"thanks\",\"thanx\",\"that\",\"that's\",\"thats\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"thence\",\"there\",\"there's\",\"thereafter\",\"thereby\",\"therefore\",\"therein\",\"theres\",\"thereupon\",\"these\",\"they\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"think\",\"third\",\"this\",\"thorough\",\"thoroughly\",\"those\",\"though\",\"three\",\"through\",\"throughout\",\"thru\",\"thus\",\"to\",\"together\",\"too\",\"took\",\"toward\",\"towards\",\"tried\",\"tries\",\"truly\",\"try\",\"trying\",\"twice\",\"two\",\"u\",\"un\",\"under\",\"unfortunately\",\"unless\",\"unlikely\",\"until\",\"unto\",\"up\",\"upon\",\"us\",\"use\",\"used\",\"useful\",\"uses\",\"using\",\"usually\",\"uucp\",\"v\",\"value\",\"various\",\"very\",\"via\",\"viz\",\"vs\",\"w\",\"want\",\"wants\",\"was\",\"wasn't\",\"way\",\"we\",\"we'd\",\"we'll\",\"we're\",\"we've\",\"welcome\",\"well\",\"went\",\"were\",\"weren't\",\"what\",\"what's\",\"whatever\",\"when\",\"whence\",\"whenever\",\"where\",\"where's\",\"whereafter\",\"whereas\",\"whereby\",\"wherein\",\"whereupon\",\"wherever\",\"whether\",\"which\",\"while\",\"whither\",\"who\",\"who's\",\"whoever\",\"whole\",\"whom\",\"whose\",\"why\",\"will\",\"willing\",\"wish\",\"with\",\"within\",\"without\",\"won't\",\"wonder\",\"would\",\"wouldn't\",\"x\",\"y\",\"yes\",\"yet\",\"you\",\"you'd\",\"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\"yourself\",\"yourselves\",\"z\",\"zero\"]}\nstopwords_json_en = set(stopwords_json['en'])\nstopwords_nltk_en = set(stopwords_en)\n\nstopwords_punct = set(punctuation)\nstoplist=set.union(stopwords_nltk_en,stopwords_punct,stopwords_json_en)\n\nprint([word for word in sentence_lowered_tokenized if word not in stoplist])","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:16.993067Z","iopub.execute_input":"2021-06-25T14:40:16.993355Z","iopub.status.idle":"2021-06-25T14:40:17.132493Z","shell.execute_reply.started":"2021-06-25T14:40:16.993327Z","shell.execute_reply":"2021-06-25T14:40:17.131418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stemming and Lemmatization","metadata":{}},{"cell_type":"code","source":"from nltk.stem import PorterStemmer\nstemmer=PorterStemmer()\nprint([stemmer.stem(word) for word in ['go','going','gone','went']])","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:17.136186Z","iopub.execute_input":"2021-06-25T14:40:17.136646Z","iopub.status.idle":"2021-06-25T14:40:17.145147Z","shell.execute_reply.started":"2021-06-25T14:40:17.136601Z","shell.execute_reply":"2021-06-25T14:40:17.14421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\nlemmatizer=WordNetLemmatizer()\nprint([lemmatizer.lemmatize(word) for word in ['go','going','gone','went']])","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:17.146449Z","iopub.execute_input":"2021-06-25T14:40:17.146746Z","iopub.status.idle":"2021-06-25T14:40:19.215838Z","shell.execute_reply.started":"2021-06-25T14:40:17.146719Z","shell.execute_reply":"2021-06-25T14:40:19.214906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# nltk.pos_tag","metadata":{}},{"cell_type":"markdown","source":"By default, the WordNetLemmatizer.lemmatize() function will assume that the word is a Noun if there's no explict POS tag in the input.\nIF so it won't give us what we want\nso we need to","metadata":{}},{"cell_type":"code","source":"from nltk.corpus import wordnet\nsentence= \"Yesterday I went to school by foot\"\nsentence1= \"went go gone going\"\nnltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence1)) #returns a tuple of (word, tg)\n\nnltk_tagged # tg is ntlk_tag","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:19.217102Z","iopub.execute_input":"2021-06-25T14:40:19.217369Z","iopub.status.idle":"2021-06-25T14:40:19.349222Z","shell.execute_reply.started":"2021-06-25T14:40:19.217343Z","shell.execute_reply":"2021-06-25T14:40:19.348398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def penn2morphy(penntag):\n    \"\"\" Converts Penn Treebank tags to WordNet. \"\"\"\n    morphy_tag = {'NN':'n', 'JJ':'a',\n                  'VB':'v', 'RB':'r'}\n    try:\n        return morphy_tag[penntag[:2]]\n    except:\n        return 'n' # if mapping isn't found, fall back to Noun.\n\n    \n[lemmatizer.lemmatize(word.lower(), pos=penn2morphy(tag)) for word, tag in nltk_tagged]","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:19.350306Z","iopub.execute_input":"2021-06-25T14:40:19.350643Z","iopub.status.idle":"2021-06-25T14:40:19.358709Z","shell.execute_reply.started":"2021-06-25T14:40:19.350602Z","shell.execute_reply":"2021-06-25T14:40:19.357769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Un autre exemple","metadata":{}},{"cell_type":"code","source":"def lemmatize_sent(text): \n    # Text input is string, returns lowercased strings.\n    return [lemmatizer.lemmatize(word.lower(), pos=penn2morphy(tag)) \n            for word, tag in nltk.pos_tag(word_tokenize(text))]\n\nlemmatize_sent('I was going to tell you anyway')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:19.359907Z","iopub.execute_input":"2021-06-25T14:40:19.36022Z","iopub.status.idle":"2021-06-25T14:40:19.375623Z","shell.execute_reply.started":"2021-06-25T14:40:19.360192Z","shell.execute_reply":"2021-06-25T14:40:19.374807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let's do all of this to sentence single_no9","metadata":{}},{"cell_type":"code","source":"def preprocessing(text):\n    stoplist_gen=set.union(stoplist,{'http'})\n    preproccessed_text=[word for word in lemmatize_sent(text) if word not in stoplist_gen]\n    for word in preproccessed_text:\n        if '//t.co/' in word:\n            preproccessed_text.remove(word)\n    return(preproccessed_text)\n    \nsingle_no9_preprocessed=preprocessing(single_no9)\nsingle_no9_preprocessed[0:5]","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:19.377058Z","iopub.execute_input":"2021-06-25T14:40:19.377443Z","iopub.status.idle":"2021-06-25T14:40:19.393795Z","shell.execute_reply.started":"2021-06-25T14:40:19.377405Z","shell.execute_reply":"2021-06-25T14:40:19.392911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CountVectorizer","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nimport pandas as pd\nsent1 = \"The quick brown fox jumps over the lazy brown dog.\"\nsent2 = \"Mr brown jumps over the lazy fox.\"\ncorpus=[sent1,sent2]\nprint(corpus)\nvectorizer=CountVectorizer()\ndoc_term_matrix=vectorizer.fit_transform(corpus)\ndata=doc_term_matrix.toarray()\nprint(vectorizer.get_feature_names())\npd.DataFrame(data,columns=vectorizer.get_feature_names())\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:19.395102Z","iopub.execute_input":"2021-06-25T14:40:19.395434Z","iopub.status.idle":"2021-06-25T14:40:19.419053Z","shell.execute_reply.started":"2021-06-25T14:40:19.395403Z","shell.execute_reply":"2021-06-25T14:40:19.41816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"doc_term_matrix.count_nonzero()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:19.420322Z","iopub.execute_input":"2021-06-25T14:40:19.420612Z","iopub.status.idle":"2021-06-25T14:40:19.425903Z","shell.execute_reply.started":"2021-06-25T14:40:19.420582Z","shell.execute_reply":"2021-06-25T14:40:19.425075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"sparse_matrix=vectorizer.transform([sent1, sent2])\n\nsparse_matrix.toarray()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:19.427439Z","iopub.execute_input":"2021-06-25T14:40:19.427724Z","iopub.status.idle":"2021-06-25T14:40:19.438377Z","shell.execute_reply.started":"2021-06-25T14:40:19.427695Z","shell.execute_reply":"2021-06-25T14:40:19.43755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Preprocessing && Vectorizing a Dataset of Sentiment Analysis","metadata":{}},{"cell_type":"markdown","source":"Dataset : fichier train :\"training.json\"\n          fichier test  :\"develop.json\"\nAnalyse-des-sentiments-des-Tweets en 3 classes : neg--> -1 pos-->1 neutre-->0","metadata":{}},{"cell_type":"code","source":"def preprocess_file(filename):\n    tweets = []\n    labels = []\n    f = open(filename)\n    for line in f:\n        tweet_dict = json.loads(line)\n        #print(tweet_dict)\n        tweets.append(preprocessing(tweet_dict[\"text\"]))\n        labels.append(int(tweet_dict[\"label\"]))\n    return tweets,labels\n","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:19.439536Z","iopub.execute_input":"2021-06-25T14:40:19.439827Z","iopub.status.idle":"2021-06-25T14:40:19.448586Z","shell.execute_reply.started":"2021-06-25T14:40:19.43979Z","shell.execute_reply":"2021-06-25T14:40:19.447798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\ntrain_data = preprocess_file('../input/dataset-analyse-des-sentiments/training.json')\ntrain_data=pd.DataFrame({\"tweets\":train_data[0],\"labels\":train_data[1]})","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:19.449731Z","iopub.execute_input":"2021-06-25T14:40:19.449992Z","iopub.status.idle":"2021-06-25T14:40:50.886554Z","shell.execute_reply.started":"2021-06-25T14:40:19.449967Z","shell.execute_reply":"2021-06-25T14:40:50.885469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = preprocess_file('../input/dataset-analyse-des-sentiments/develop.json')\ntest_data=pd.DataFrame({\"tweets\":test_data[0],\"labels\":test_data[1]})","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:50.887973Z","iopub.execute_input":"2021-06-25T14:40:50.888576Z","iopub.status.idle":"2021-06-25T14:40:54.449964Z","shell.execute_reply.started":"2021-06-25T14:40:50.88853Z","shell.execute_reply":"2021-06-25T14:40:54.449036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:54.451442Z","iopub.execute_input":"2021-06-25T14:40:54.45183Z","iopub.status.idle":"2021-06-25T14:40:54.462788Z","shell.execute_reply.started":"2021-06-25T14:40:54.451778Z","shell.execute_reply":"2021-06-25T14:40:54.462167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['tweets']\n","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:54.463649Z","iopub.execute_input":"2021-06-25T14:40:54.464005Z","iopub.status.idle":"2021-06-25T14:40:54.478458Z","shell.execute_reply.started":"2021-06-25T14:40:54.463979Z","shell.execute_reply":"2021-06-25T14:40:54.477874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:54.479286Z","iopub.execute_input":"2021-06-25T14:40:54.47963Z","iopub.status.idle":"2021-06-25T14:40:54.494452Z","shell.execute_reply.started":"2021-06-25T14:40:54.479604Z","shell.execute_reply":"2021-06-25T14:40:54.493494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.iloc[16804,0]","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:54.495415Z","iopub.execute_input":"2021-06-25T14:40:54.495667Z","iopub.status.idle":"2021-06-25T14:40:54.506451Z","shell.execute_reply.started":"2021-06-25T14:40:54.495643Z","shell.execute_reply":"2021-06-25T14:40:54.505408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.iloc[0,0]","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:54.507903Z","iopub.execute_input":"2021-06-25T14:40:54.508351Z","iopub.status.idle":"2021-06-25T14:40:54.516869Z","shell.execute_reply.started":"2021-06-25T14:40:54.508313Z","shell.execute_reply":"2021-06-25T14:40:54.515847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.iloc[12,0]","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:54.517773Z","iopub.execute_input":"2021-06-25T14:40:54.518136Z","iopub.status.idle":"2021-06-25T14:40:54.528261Z","shell.execute_reply.started":"2021-06-25T14:40:54.518106Z","shell.execute_reply":"2021-06-25T14:40:54.527611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.iloc[93,0]","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:54.52898Z","iopub.execute_input":"2021-06-25T14:40:54.529322Z","iopub.status.idle":"2021-06-25T14:40:54.538348Z","shell.execute_reply.started":"2021-06-25T14:40:54.529293Z","shell.execute_reply":"2021-06-25T14:40:54.537753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization","metadata":{}},{"cell_type":"code","source":"label_mapping={1:'Positive',-1:'Negative',0:'Neutral'}\nY=train_data['labels'].map(label_mapping)\nY","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:54.539139Z","iopub.execute_input":"2021-06-25T14:40:54.539475Z","iopub.status.idle":"2021-06-25T14:40:54.553445Z","shell.execute_reply.started":"2021-06-25T14:40:54.53945Z","shell.execute_reply":"2021-06-25T14:40:54.552571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set(font_scale=1.4)\nY.value_counts(normalize=True).plot(kind='bar', figsize=(7, 6), rot=0)\nplt.xlabel(\"Sentiment Polarity\", labelpad=14)\nplt.ylabel(\"% of each category in the Dataset\", labelpad=14)\nplt.title(\"Distribution of tweets by polarity \", y=1.02);\n","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:54.554756Z","iopub.execute_input":"2021-06-25T14:40:54.555035Z","iopub.status.idle":"2021-06-25T14:40:54.828235Z","shell.execute_reply.started":"2021-06-25T14:40:54.555Z","shell.execute_reply":"2021-06-25T14:40:54.82725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Resampling the unbalanced data","metadata":{}},{"cell_type":"code","source":"from sklearn.utils import resample\n\ndf_neg=(train_data[train_data[\"labels\"]==-1]).sample(n=2520,random_state=42)\ndf_neu=(train_data[train_data[\"labels\"]==0]).sample(n=2520,random_state=42)\ndf_pos=(train_data[train_data[\"labels\"]==1]).sample(n=2520,random_state=42)\n\ntrain_data=pd.concat([df_neg,df_neu,df_pos])","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:54.829406Z","iopub.execute_input":"2021-06-25T14:40:54.829669Z","iopub.status.idle":"2021-06-25T14:40:54.846546Z","shell.execute_reply.started":"2021-06-25T14:40:54.829643Z","shell.execute_reply":"2021-06-25T14:40:54.845675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TF-IDF vectorization","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n\ndef None_Function(doc):\n    return doc\nvectorizer = TfidfVectorizer(\n                             tokenizer=None_Function,\n                             preprocessor=None_Function,\n                             sublinear_tf = True,\n                             use_idf = True)\ntrain_vectors = vectorizer.fit_transform(train_data['tweets'])\n\nlen(vectorizer.vocabulary_)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:54.847678Z","iopub.execute_input":"2021-06-25T14:40:54.847957Z","iopub.status.idle":"2021-06-25T14:40:54.985848Z","shell.execute_reply.started":"2021-06-25T14:40:54.847928Z","shell.execute_reply":"2021-06-25T14:40:54.985084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_vectors.toarray()\n#pd.DataFrame(data,columns=vec.get_feature_names())","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:54.986892Z","iopub.execute_input":"2021-06-25T14:40:54.987331Z","iopub.status.idle":"2021-06-25T14:40:55.306835Z","shell.execute_reply.started":"2021-06-25T14:40:54.987289Z","shell.execute_reply":"2021-06-25T14:40:55.305968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_vectors.count_nonzero()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:55.308133Z","iopub.execute_input":"2021-06-25T14:40:55.308484Z","iopub.status.idle":"2021-06-25T14:40:55.315902Z","shell.execute_reply.started":"2021-06-25T14:40:55.308454Z","shell.execute_reply":"2021-06-25T14:40:55.314957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_vectors.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:55.317091Z","iopub.execute_input":"2021-06-25T14:40:55.317422Z","iopub.status.idle":"2021-06-25T14:40:55.325536Z","shell.execute_reply.started":"2021-06-25T14:40:55.317394Z","shell.execute_reply":"2021-06-25T14:40:55.324575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_vectors = vectorizer.transform(test_data['tweets'])\ntest_vectors.toarray()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:55.326953Z","iopub.execute_input":"2021-06-25T14:40:55.327503Z","iopub.status.idle":"2021-06-25T14:40:55.422313Z","shell.execute_reply.started":"2021-06-25T14:40:55.327463Z","shell.execute_reply":"2021-06-25T14:40:55.42118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_vectors.count_nonzero()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:55.423466Z","iopub.execute_input":"2021-06-25T14:40:55.423736Z","iopub.status.idle":"2021-06-25T14:40:55.429266Z","shell.execute_reply.started":"2021-06-25T14:40:55.42371Z","shell.execute_reply":"2021-06-25T14:40:55.42825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_vectors.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:55.43053Z","iopub.execute_input":"2021-06-25T14:40:55.430823Z","iopub.status.idle":"2021-06-25T14:40:55.442387Z","shell.execute_reply.started":"2021-06-25T14:40:55.430791Z","shell.execute_reply":"2021-06-25T14:40:55.441364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_tags=train_data['labels']\ntrain_tags[0]","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:55.443745Z","iopub.execute_input":"2021-06-25T14:40:55.444093Z","iopub.status.idle":"2021-06-25T14:40:55.453459Z","shell.execute_reply.started":"2021-06-25T14:40:55.44405Z","shell.execute_reply":"2021-06-25T14:40:55.452529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_tags.iloc[0]","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:55.454729Z","iopub.execute_input":"2021-06-25T14:40:55.455034Z","iopub.status.idle":"2021-06-25T14:40:55.464745Z","shell.execute_reply.started":"2021-06-25T14:40:55.454995Z","shell.execute_reply":"2021-06-25T14:40:55.463824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\ntrain_tags=np.array([[train_tags.iloc[i]] for i in range(len(train_tags))])\ntrain_tags","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:55.465818Z","iopub.execute_input":"2021-06-25T14:40:55.466108Z","iopub.status.idle":"2021-06-25T14:40:55.559275Z","shell.execute_reply.started":"2021-06-25T14:40:55.466079Z","shell.execute_reply":"2021-06-25T14:40:55.55843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_tags=test_data['labels']\ntest_tags=np.array([[test_tags.iloc[i]] for i in range(len(test_tags))])\ntest_tags","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:55.560351Z","iopub.execute_input":"2021-06-25T14:40:55.560608Z","iopub.status.idle":"2021-06-25T14:40:55.585697Z","shell.execute_reply.started":"2021-06-25T14:40:55.560583Z","shell.execute_reply":"2021-06-25T14:40:55.584774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Classification\n# Naive Bayes","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nclf = MultinomialNB() \n\n# To train the classifier, simple do \nclf.fit(train_vectors, train_tags) ","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:55.587064Z","iopub.execute_input":"2021-06-25T14:40:55.587368Z","iopub.status.idle":"2021-06-25T14:40:55.6113Z","shell.execute_reply.started":"2021-06-25T14:40:55.587333Z","shell.execute_reply":"2021-06-25T14:40:55.610596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\npredictions= clf.predict(test_vectors)\n\nprint('Polarity prediction test_accuracy = {}'.format(\n        accuracy_score(predictions, test_tags) * 100)\n     )","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:55.612271Z","iopub.execute_input":"2021-06-25T14:40:55.612671Z","iopub.status.idle":"2021-06-25T14:40:55.618334Z","shell.execute_reply.started":"2021-06-25T14:40:55.612634Z","shell.execute_reply":"2021-06-25T14:40:55.617581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_train= clf.predict(train_vectors)\n\nprint('Polarity prediction train_accuracy = {}'.format(\n        accuracy_score(predictions_train, train_tags) * 100)\n     )","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:55.619309Z","iopub.execute_input":"2021-06-25T14:40:55.619682Z","iopub.status.idle":"2021-06-25T14:40:55.630266Z","shell.execute_reply.started":"2021-06-25T14:40:55.619655Z","shell.execute_reply":"2021-06-25T14:40:55.629376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# K-means","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import TruncatedSVD\ntrain_vectors_2D = TruncatedSVD(n_components=2).fit_transform(train_vectors)\ntrain_vectors_2D","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:55.631286Z","iopub.execute_input":"2021-06-25T14:40:55.631551Z","iopub.status.idle":"2021-06-25T14:40:55.758111Z","shell.execute_reply.started":"2021-06-25T14:40:55.631526Z","shell.execute_reply":"2021-06-25T14:40:55.756894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=3,n_init=50,max_iter=300)\nkmeans.fit(train_vectors_2D)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:40:55.7691Z","iopub.execute_input":"2021-06-25T14:40:55.769546Z","iopub.status.idle":"2021-06-25T14:41:02.998745Z","shell.execute_reply.started":"2021-06-25T14:40:55.769501Z","shell.execute_reply":"2021-06-25T14:41:02.998039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_kmeans = kmeans.predict(train_vectors_2D)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:41:02.999939Z","iopub.execute_input":"2021-06-25T14:41:03.00047Z","iopub.status.idle":"2021-06-25T14:41:03.011266Z","shell.execute_reply.started":"2021-06-25T14:41:03.000435Z","shell.execute_reply":"2021-06-25T14:41:03.010122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_kmeans==0","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:41:03.014997Z","iopub.execute_input":"2021-06-25T14:41:03.015354Z","iopub.status.idle":"2021-06-25T14:41:03.023143Z","shell.execute_reply.started":"2021-06-25T14:41:03.015321Z","shell.execute_reply":"2021-06-25T14:41:03.022149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The lowest SSE value\nkmeans.inertia_","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:41:03.024532Z","iopub.execute_input":"2021-06-25T14:41:03.02487Z","iopub.status.idle":"2021-06-25T14:41:03.032556Z","shell.execute_reply.started":"2021-06-25T14:41:03.024841Z","shell.execute_reply":"2021-06-25T14:41:03.031789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Final locations of the centroid\ncenters=kmeans.cluster_centers_","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:41:03.033637Z","iopub.execute_input":"2021-06-25T14:41:03.033907Z","iopub.status.idle":"2021-06-25T14:41:03.040279Z","shell.execute_reply.started":"2021-06-25T14:41:03.033882Z","shell.execute_reply":"2021-06-25T14:41:03.039385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The number of iterations required to converge\nkmeans.n_iter_","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:41:03.04456Z","iopub.execute_input":"2021-06-25T14:41:03.044819Z","iopub.status.idle":"2021-06-25T14:41:03.054537Z","shell.execute_reply.started":"2021-06-25T14:41:03.044794Z","shell.execute_reply":"2021-06-25T14:41:03.053616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:41:03.055511Z","iopub.execute_input":"2021-06-25T14:41:03.055772Z","iopub.status.idle":"2021-06-25T14:41:03.061906Z","shell.execute_reply.started":"2021-06-25T14:41:03.055747Z","shell.execute_reply":"2021-06-25T14:41:03.06111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(train_vectors_2D[Y_kmeans==0,0],train_vectors_2D[Y_kmeans==0,1],s=20,c='red')\nplt.scatter(train_vectors_2D[Y_kmeans==1,0],train_vectors_2D[Y_kmeans==1,1],s=20,c='blue')\nplt.scatter(train_vectors_2D[Y_kmeans==2,0],train_vectors_2D[Y_kmeans==2,1],s=20,c='green')\n\nplt.scatter(centers[0][0],centers[0][1],marker=\"*\",s=200,c='white')\nplt.scatter(centers[1][0],centers[1][1],marker=\"*\",s=200,c='white')\nplt.scatter(centers[2][0],centers[2][1],marker=\"*\",s=200,c='white')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:41:03.06886Z","iopub.execute_input":"2021-06-25T14:41:03.069196Z","iopub.status.idle":"2021-06-25T14:41:03.28516Z","shell.execute_reply.started":"2021-06-25T14:41:03.069164Z","shell.execute_reply":"2021-06-25T14:41:03.284188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score=accuracy_score(Y_kmeans,train_tags)\naccuracy_score","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:41:03.288559Z","iopub.execute_input":"2021-06-25T14:41:03.288837Z","iopub.status.idle":"2021-06-25T14:41:03.295991Z","shell.execute_reply.started":"2021-06-25T14:41:03.28881Z","shell.execute_reply":"2021-06-25T14:41:03.294926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random forest","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import TruncatedSVD\nn=int(0.6*17209)\nsvd = TruncatedSVD(n_components=10325)\ntrain_vectors=svd.fit_transform(train_vectors)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T14:41:03.29708Z","iopub.execute_input":"2021-06-25T14:41:03.297388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_vectors","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(svd.explained_variance_ratio_.sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_vectors.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_vectors.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_vectors = svd.transform(test_vectors)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_vectors","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_vectors.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt \nfrom sklearn.ensemble import RandomForestClassifier\n\n#prediction=rf.predict(test_vectors)\n\n#accuracy_score=accuracy_score(prediction,test_tags)\n#accuracy_score\nn_estimators=[10,50,70,100,150,200,300,400]\nscore=[]\nfor x in n_estimators:\n    rf=RandomForestClassifier(n_estimators=x,max_features='sqrt',random_state=0)\n    rf.fit(train_vectors, train_tags.ravel())\n    score.append(rf.score(test_vectors,test_tags))\n\nplt.plot(n_estimators,score)\nplt.xlabel(\"nombre d'estimateurs (arbres de d√©cision)\")\nplt.ylabel(\" Accuracy score\")\nplt.title(\"The score variation as a function of the number of estimators\" );\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf=RandomForestClassifier(n_estimators=200,max_features='sqrt',random_state=0)\nrf.fit(train_vectors, train_tags.ravel())\nY_pred=rf.predict(test_vectors)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf.score(test_vectors,test_tags)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Plot confusion matrix\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix,classification_report\n\ncf_matrix = confusion_matrix(test_tags,Y_pred )\n\ncf_matrix\nprint(classification_report(test_tags,Y_pred))\n\ndf_cm = pd.DataFrame(cf_matrix , index = [i for i in [-1,0,1]],columns = [i for i in [-1,0,1]])\nplt.figure(figsize = (10,7))\nsns.heatmap(df_cm/np.sum(df_cm), annot=True, \n            fmt='.2%')\nplt.xlabel('Predicted Class')\nplt.ylabel('True Class')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter Tuning the Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(random_state = 42)\nfrom pprint import pprint\n# Look at parameters used by our current forest\nprint('Parameters currently in use:\\n')\npprint(rf.get_params())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\npprint(random_grid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_vectors.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Use the random grid to search for best hyperparameters\n# First create the base model to tune\nrf = RandomForestClassifier()\n# Random search of parameters, using 3 fold cross validation, \n# search across 100 different combinations, and use all available cores\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv =3 , verbose=2, random_state=42, n_jobs = -1)\n# n_jobs = Number of jobs to run in parallel\n#n_iter: controls the number of different combinations to try\n#cv : number of folds to use for cross validation\n\n# Fit the random search model\nrf_random.fit(train_vectors, train_tags.ravel())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nrf_random.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.\nrf=RandomForestClassifier(bootstrap=False,n_estimators=1000,max_features='auto',\n                          min_samples_split=10,min_samples_leaf=1,max_depth=80,random_state=42)\nrf.fit(train_vectors, train_tags.ravel())\nrf.score(test_vectors,test_tags)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Support Vectors Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn import svm\nfrom sklearn.metrics import accuracy_score\n\n# Perform classification with SVM, kernel=linear\nclassifier_linear = svm.SVC(kernel='linear') # SVC a linear kernel\n\nclassifier_linear.fit(train_vectors, train_tags)\n\nprediction_linear = classifier_linear.predict(test_vectors)\n\nResultat=accuracy_score(test_tags,prediction_linear)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Resultat","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Plot confusion matrix\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix,classification_report\n\ncf_matrix = confusion_matrix(test_tags,prediction_linear )\n\ncf_matrix\nprint(classification_report(test_tags,prediction_linear))\n\ndf_cm = pd.DataFrame(cf_matrix , index = [i for i in [-1,0,1]],columns = [i for i in [-1,0,1]])\nplt.figure(figsize = (10,7))\nsns.heatmap(df_cm/np.sum(df_cm), annot=True, \n            fmt='.2%')\nplt.xlabel('Predicted Class')\nplt.ylabel('True Class')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Deep Learning","metadata":{}},{"cell_type":"code","source":"#  neural network with keras \nfrom keras.models import Sequential\nfrom keras.layers import Dense\n# define the keras model\nmodel = Sequential()\nmodel.add(Dense(40, input_shape=(7560,), activation='sigmoid'))\nmodel.add(Dense(200, activation='relu'))\nmodel.add(Dense(40, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n# compile the keras model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n# fit the keras model on the dataset\nmodel.fit(train_vectors, train_tags, epochs=2000, batch_size=100)\n# fit the keras model on the dattest_tagsodel.fit(train_vectors, train_tags, epochs=2000, batch_size=100)\n#The batch size defines the number of samples that will be propagated through the network.\n# One Epoch is when an ENTIRE dataset is passed forward and backward through the neural network only ONCE.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred=model.predict(test_vectors)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Plot confusion matrix\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix,classification_report\n\ncf_matrix = confusion_matrix(test_tags,Y_pred )\n\ncf_matrix\nprint(classification_report(test_tags,Y_pred))\n\ndf_cm = pd.DataFrame(cf_matrix , index = [i for i in [-1,0,1]],columns = [i for i in [-1,0,1]])\nplt.figure(figsize = (10,7))\nsns.heatmap(df_cm/np.sum(df_cm), annot=True, \n            fmt='.2%')\nplt.xlabel('Predicted Class')\nplt.ylabel('True Class')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate the keras model on the test \n_, accuracy = model.evaluate(train_vectors, train_tags)\nprint('Train Accuracy: %.2f' % (accuracy*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate the keras model on the test \n_, accuracy = model.evaluate(test_vectors, test_tags)\nprint('Test Accuracy: %.2f' % (accuracy*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}