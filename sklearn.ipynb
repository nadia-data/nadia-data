{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sklearn.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOfF6OE1iWqd7HwrbcyJplC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nadia-data/nadia-data/blob/main/sklearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9VGbmukifJO"
      },
      "source": [
        "!pip install scikit-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrX4f8lGlknW"
      },
      "source": [
        "!pip install matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kn0VBTBaPWf0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x=[i for i in range(10)]\n",
        "y=[2*i for i in range(10)]\n",
        "print(x,y)\n",
        "plt.scatter(x,y)\n",
        "plt.xlabel('hada')\n",
        "plt.ylabel('howa')\n",
        "plt.title('hadahowa')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5RGNomsRDWg"
      },
      "source": [
        "from sklearn import datasets # librairie pour la dataset\n",
        "from sklearn.model_selection import train_test_split  # prendre un % train et % test\n",
        "import sklearn.metrics as sk # metrics contient r2_score,mean_squared_error,classification_report\n",
        "from sklearn import neighbors\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "iris=datasets.load_iris()\n",
        "\n",
        "x=iris.data\n",
        "y=iris.target\n",
        "data=[0 for i in range( len(y))]\n",
        "for i in range (len(y)):\n",
        "   data[i]=x[i].tolist () + [y[i]]\n",
        "\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(x,y,test_size=0.5)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "############\n",
        "from sklearn.metrics import classification_report\n",
        "y_true = [0, 1, 2, 2, 2]\n",
        "y_pred = [0, 0, 2, 2, 1]\n",
        "target_names = ['class 0', 'class 1', 'class 2']\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))\n",
        "\n",
        "###########\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "data_car=pd.read_csv('car.DATA')\n",
        "data_car.columns = ['buying','maint','doors','persons','lug_boot','safety','class']#ajouter les titres des coloumns\n",
        "Y=data_car['class']\n",
        "X=data_car.loc[:, data_car.columns != 'class'].values #.values == to array\n",
        "#X=data_car[[\"buying\",\"maint\",\"safety\"]].values\n",
        "####1er methode####\n",
        "Le=LabelEncoder() # ya9bal fa9At array!!!!!!!!\n",
        "for i in range(len(X[0])):\n",
        "    X[:,i]=Le.fit_transform(X[:,i])\n",
        "####2eme methode####\n",
        "label_mapping={'unacc':0,'acc':1,'good':2,'vgood':3}\n",
        "Y=data_car['class'].map(label_mapping) # blasst hadi hatti hadi\n",
        "Y=np.array(Y)\n",
        "\n",
        "\n",
        "knn=neighbors.KNeighborsClassifier(n_neighbors=25,weights='uniform')# uniform== effet égale pour tout les voisins, distance== valorise les voisins proches\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)\n",
        "knn.fit(X_train,Y_train)\n",
        "Y_pred=knn.predict(X_test)\n",
        "score=sk.r2_score(Y_test,Y_pred)\n",
        "MSE=sk.mean_squared_error(Y_test,Y_pred)\n",
        "accuracy=sk.accuracy_score(Y_test,Y_pred)\n",
        "\n",
        "\n",
        "\n",
        "######  SVM ########\n",
        "\n",
        "from sklearn import datasets # librairie pour la dataset\n",
        "from sklearn.model_selection import train_test_split  # prendre un % train et % test\n",
        "import sklearn.metrics as sk\n",
        "from sklearn import svm\n",
        "\n",
        "iris=datasets.load_iris()\n",
        "X=iris.data\n",
        "Y=iris.target\n",
        "classes=iris.target_names.tolist()\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)\n",
        "\n",
        "model=svm.SVC()\n",
        "model.fit(X_train,Y_train)\n",
        "Y_pred=model.predict(X_test)\n",
        "erreur=sk.mean_absolute_error(Y_test,Y_pred)\n",
        "score=sk.accuracy_score(Y_test,Y_pred)\n",
        "\n",
        "for i in range(len(Y_pred)):\n",
        "   print(classes[Y_pred[i]])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-46WVVFmDVU"
      },
      "source": [
        "#selectinner des lignes avec conditions pandas\n",
        "#m1\n",
        "data_FC[ data_FC['Cover_Type'] == 5]\n",
        "#m2\n",
        "df_mask=data_FC['Cover_Type']==3\n",
        "positions = np.flatnonzero(df_mask)\n",
        "filtered_df=df.iloc[positions]\n",
        "print(filtered_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d11uEqPiRN3t"
      },
      "source": [
        "### save model ###\n",
        "from sklearn.externals import joblib\n",
        "filename=\"bn.sav\"# le fichier li ghadi ndiro fih notre modèle\n",
        "joblib.dump(model,filename)# safi hnaya dakhlna l modéle dialna\n",
        "###open model ###\n",
        "modle=joblib.load(filename)#smia dial fichier a rass taro "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4HDxmVwSVn4"
      },
      "source": [
        "###train test split ###\n",
        "# kifach kansepariw data en data training et data testing\n",
        "from sklearn import datasets \n",
        "import numpy as np \n",
        "iris=datasets.load_iris()\n",
        "###sparere notre data en featurs and label\n",
        "X=iris.data\n",
        "Y=iris.target\n",
        "#print(\"featurs:\",X,\"\\nlabel:\",Y)\n",
        "#print(X.shape)\n",
        "#print(Y.shape)\n",
        "from sklearn.model_selection import train_test_split # librairie pour separer notre data\n",
        "classes=iris.target_names\n",
        "#classes.tolist()# hadi ghir kat3tik l resultat blma tbadal type \n",
        "#print(type(classes))#had l3iba diam ghir tkatbi bla print katsla7 ghir mli katkoun fi lakher :ndarray\n",
        "classes=classes.tolist() # hadi sf katbadal ga3 type\n",
        "#type(classes): list\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,Y, test_size=0.2)\n",
        "print(X_train.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5We-GFg1BPp"
      },
      "source": [
        "# knn aproche \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import neighbors #knn approche\n",
        "from sklearn import metrics #calculer les scores \n",
        "from sklearn.model_selection import train_test_split  # prendre un % train et % test\n",
        "from sklearn.preprocessing import LabelEncoder # associer des valeurs reeles comme 0 1 ect...\n",
        "data_car=pd.read_csv('car.data')\n",
        "#data_car.head()\n",
        "data_car.columns = ['buying','maint','doors','persons','lug_boot','safety','class']#ajouter les titres des coloumns\n",
        "#data_car.head()\n",
        "X=data_car[[\"buying\",\"maint\",\"safety\"]].values\n",
        "Y=data_car[[\"class\"]]\n",
        "\"\"\"converting our data\"\"\"\n",
        "le = LabelEncoder()#only array\n",
        "#converting our x\n",
        "for i in range(len(X[0])):\n",
        "  X[:,i]=le.fit_transform(X[:,i])\n",
        "#converting the y\n",
        "label_mapping={'unacc':0,\"acc\":1,\"good\":2,\"vgood\":3}\n",
        "Y[\"class\"]=Y[\"class\"].map(label_mapping)\n",
        "Y=np.array(Y)\n",
        "print(type(Y[0]))\n",
        "\"\"\"creating our model\"\"\"\n",
        "knn= neighbors.KNeighborsClassifier(n_neighbors=25,weights=\"uniform\")\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,Y, test_size=0.2)\n",
        "knn.fit(X_train,y_train)\n",
        "y_pred=knn.predict(X_test)\n",
        "accurcy= metrics.accuracy_score(y_test,y_pred)\n",
        "print(accurcy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep923KTAdJrr"
      },
      "source": [
        "###svm approche\n",
        "from sklearn import datasets \n",
        "from sklearn import svm\n",
        "import numpy as np \n",
        "iris=datasets.load_iris()\n",
        "X=iris.data\n",
        "Y=iris.target\n",
        "classes=iris.target_names.tolist()\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,Y, test_size=0.2)\n",
        "model=svm.SVC()\n",
        "model.fit(X_train,y_train)\n",
        "y_pred=model.predict(X_test)\n",
        "accurcy=metrics.accuracy_score(y_test,y_pred)\n",
        "\"\"\"\n",
        "for i in range(len(y_pred)):\n",
        "  print(classes[y_pred[i]])#kola numra raha bi smia selon les classes\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG4RzeMbvqbp"
      },
      "source": [
        "#linear regression \n",
        "from sklearn import datasets,linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "boston= datasets.load_boston()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}