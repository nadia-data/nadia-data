{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sklearn.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNNTnNViPpQ9lr4gFLqOl4+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nadia-data/nadia-data/blob/main/sklearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9VGbmukifJO"
      },
      "source": [
        "!pip install scikit-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrX4f8lGlknW"
      },
      "source": [
        "!pip install matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kn0VBTBaPWf0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x=[i for i in range(10)]\n",
        "y=[2*i for i in range(10)]\n",
        "print(x,y)\n",
        "plt.scatter(x,y)\n",
        "plt.xlabel('hada')\n",
        "plt.ylabel('howa')\n",
        "plt.title('hadahowa')\n",
        "l=['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'outcome']\n",
        "len(l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5RGNomsRDWg"
      },
      "source": [
        "from sklearn import datasets # librairie pour la dataset\n",
        "from sklearn.model_selection import train_test_split  # prendre un % train et % test\n",
        "import sklearn.metrics as sk # metrics contient r2_score,mean_squared_error,classification_report\n",
        "from sklearn import neighbors\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "iris=datasets.load_iris()\n",
        "\n",
        "x=iris.data\n",
        "y=iris.target\n",
        "data=[0 for i in range( len(y))]\n",
        "for i in range (len(y)):\n",
        "   data[i]=x[i].tolist () + [y[i]]\n",
        "\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(x,y,test_size=0.5)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "############\n",
        "from sklearn.metrics import classification_report\n",
        "y_true = [0, 1, 2, 2, 2]\n",
        "y_pred = [0, 0, 2, 2, 1]\n",
        "target_names = ['class 0', 'class 1', 'class 2']\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))\n",
        "\n",
        "###########\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "data_car=pd.read_csv('car.DATA')\n",
        "data_car.columns = ['buying','maint','doors','persons','lug_boot','safety','class']#ajouter les titres des coloumns\n",
        "Y=data_car['class']\n",
        "X=data_car.loc[:, data_car.columns != 'class'].values #.values == to array\n",
        "#X=data_car[[\"buying\",\"maint\",\"safety\"]].values\n",
        "####1er methode####\n",
        "Le=LabelEncoder() # ya9bal fa9At array!!!!!!!!\n",
        "for i in range(len(X[0])):\n",
        "    X[:,i]=Le.fit_transform(X[:,i])\n",
        "####2eme methode####\n",
        "label_mapping={'unacc':0,'acc':1,'good':2,'vgood':3}\n",
        "Y=data_car['class'].map(label_mapping) # blasst hadi hatti hadi\n",
        "Y=np.array(Y)\n",
        "\n",
        "\n",
        "knn=neighbors.KNeighborsClassifier(n_neighbors=25,weights='uniform')# uniform== effet égale pour tout les voisins, distance== valorise les voisins proches\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)\n",
        "knn.fit(X_train,Y_train)\n",
        "Y_pred=knn.predict(X_test)\n",
        "score=sk.r2_score(Y_test,Y_pred)\n",
        "MSE=sk.mean_squared_error(Y_test,Y_pred)\n",
        "accuracy=sk.accuracy_score(Y_test,Y_pred)\n",
        "\n",
        "\n",
        "\n",
        "######  SVM ########\n",
        "\n",
        "from sklearn import datasets # librairie pour la dataset\n",
        "from sklearn.model_selection import train_test_split  # prendre un % train et % test\n",
        "import sklearn.metrics as sk\n",
        "from sklearn import svm\n",
        "\n",
        "iris=datasets.load_iris()\n",
        "X=iris.data\n",
        "Y=iris.target\n",
        "classes=iris.target_names.tolist()\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)\n",
        "\n",
        "model=svm.SVC()\n",
        "model.fit(X_train,Y_train)\n",
        "Y_pred=model.predict(X_test)\n",
        "erreur=sk.mean_absolute_error(Y_test,Y_pred)\n",
        "score=sk.accuracy_score(Y_test,Y_pred)\n",
        "\n",
        "for i in range(len(Y_pred)):\n",
        "   print(classes[Y_pred[i]])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8orwqpt9jYAI"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "data_car=pd.read_csv('car.data')\n",
        "data_car.columns = ['buying','maint','doors','persons','lug_boot','safety','class']#ajouter les titres des coloumns\n",
        "Y=data_car['class']\n",
        "X=data_car.loc[:, data_car.columns != 'class'].values #.values == to array\n",
        "#X=data_car[[\"buying\",\"maint\",\"safety\"]].values\n",
        "####1er methode####\n",
        "Le=LabelEncoder() # ya9bal fa9At array!!!!!!!!\n",
        "for i in range(len(X[0])):\n",
        "    X[:,i]=Le.fit_transform(X[:,i])\n",
        "####2eme methode####\n",
        "label_mapping={'unacc':'p','acc':'1','good':'2','vgood':'l'}\n",
        "Y=data_car['class'].map(label_mapping) # blasst hadi hatti hadi\n",
        "Y=np.array(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d11uEqPiRN3t"
      },
      "source": [
        "### save model ###\n",
        "from sklearn.externals import joblib\n",
        "filename=\"bn.sav\"# le fichier li ghadi ndiro fih notre modèle\n",
        "joblib.dump(model,filename)# safi hnaya dakhlna l modéle dialna\n",
        "###open model ###\n",
        "modle=joblib.load(filename)#smia dial fichier a rass taro "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4HDxmVwSVn4"
      },
      "source": [
        "###train test split ###\n",
        "# kifach kansepariw data en data training et data testing\n",
        "from sklearn import datasets \n",
        "import numpy as np \n",
        "iris=datasets.load_iris()\n",
        "###sparere notre data en featurs and label\n",
        "X=iris.data\n",
        "Y=iris.target\n",
        "#print(\"featurs:\",X,\"\\nlabel:\",Y)\n",
        "#print(X.shape)\n",
        "#print(Y.shape)\n",
        "from sklearn.model_selection import train_test_split # librairie pour separer notre data\n",
        "classes=iris.target_names\n",
        "#classes.tolist()# hadi ghir kat3tik l resultat blma tbadal type \n",
        "#print(type(classes))#had l3iba diam ghir tkatbi bla print katsla7 ghir mli katkoun fi lakher :ndarray\n",
        "classes=classes.tolist() # hadi sf katbadal ga3 type\n",
        "#type(classes): list\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,Y, test_size=0.2)\n",
        "print(X_train.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5We-GFg1BPp"
      },
      "source": [
        "# knn aproche \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import neighbors #knn approche\n",
        "from sklearn import metrics #calculer les scores \n",
        "from sklearn.model_selection import train_test_split  # prendre un % train et % test\n",
        "from sklearn.preprocessing import LabelEncoder # associer des valeurs reeles comme 0 1 ect...\n",
        "data_car=pd.read_csv('car.data')\n",
        "#data_car.head()\n",
        "data_car.columns = ['buying','maint','doors','persons','lug_boot','safety','class']#ajouter les titres des coloumns\n",
        "#data_car.head()\n",
        "X=data_car[[\"buying\",\"maint\",\"safety\"]].values\n",
        "print(type(X))\n",
        "Y=data_car[[\"class\"]]\n",
        "\"\"\"converting our data\"\"\"\n",
        "le = LabelEncoder()#only array\n",
        "#converting our x\n",
        "for i in range(len(X[0])):\n",
        "  X[:,i]=le.fit_transform(X[:,i])\n",
        "#converting the y\n",
        "label_mapping={'unacc':0,\"acc\":1,\"good\":2,\"vgood\":3}\n",
        "Y[\"class\"]=Y[\"class\"].map(label_mapping)\n",
        "Y=np.array(Y)\n",
        "print(type(Y[0]))\n",
        "\"\"\"creating our model\"\"\"\n",
        "knn= neighbors.KNeighborsClassifier(n_neighbors=25,weights=\"uniform\")\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,Y, test_size=0.2)\n",
        "knn.fit(X_train,y_train)\n",
        "y_pred=knn.predict(X_test)\n",
        "accurcy= metrics.accuracy_score(y_test,y_pred)\n",
        "print(accurcy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8ifi6gDv534"
      },
      "source": [
        "!pip install  rfflearn\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9wVNvO_nBYc"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import SVR\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# #############################################################################\n",
        "# Generate sample data\n",
        "X = np.sort(5 * np.random.rand(40, 1), axis=0)\n",
        "y = np.sin(X).ravel()\n",
        "# Add noise to targets\n",
        "y[::5] += 3 * (0.5 - np.random.rand(8))\n",
        "#############################################################################\n",
        "# Fit regression model\n",
        "svr_rbf = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)\n",
        "svr_lin = SVR(kernel='linear', C=100, gamma='auto')\n",
        "svr_poly = SVR(kernel='poly', C=100, gamma='auto', degree=3, epsilon=.1,\n",
        "               coef0=1)\n",
        "lw = 2\n",
        "\n",
        "svrs = [svr_rbf, svr_lin, svr_poly]\n",
        "kernel_label = ['RBF', 'Linear', 'Polynomial']\n",
        "model_color = ['m', 'c', 'g']\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 10), sharey=True)\n",
        "for ix, svr in enumerate(svrs):\n",
        "    axes[ix].plot(X, svr.fit(X, y).predict(X), color=model_color[ix],lw=lw,\n",
        "                  label='{} model'.format(kernel_label[ix]))\n",
        "    axes[ix].scatter(X[svr.support_], y[svr.support_], facecolor=\"none\",\n",
        "                     edgecolor=model_color[ix], s=50,\n",
        "                     label='{} support vectors'.format(kernel_label[ix]))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep923KTAdJrr"
      },
      "source": [
        "###svm approche\n",
        "from sklearn import datasets \n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "import numpy as np \n",
        "iris=datasets.load_iris()\n",
        "len(iris)\n",
        "X=iris.data\n",
        "Y=iris.target\n",
        "classes=iris.target_names.tolist()\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,Y, test_size=0.2)\n",
        "model=svm.SVC()\n",
        "model.fit(X_train,y_train)\n",
        "y_pred=model.predict(X_test)\n",
        "accurcy=metrics.accuracy_score(y_test,y_pred)\n",
        "print(accurcy)\n",
        "\"\"\"\n",
        "for i in range(len(y_pred)):\n",
        "  print(classes[y_pred[i]])#kola numra raha bi smia selon les classes\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E99lHhzpPzSq"
      },
      "source": [
        "from sklearn import datasets \n",
        "from sklearn import svm\n",
        "import numpy as np \n",
        "iris=datasets.load_iris()\n",
        "X=iris.data\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG4RzeMbvqbp"
      },
      "source": [
        "#linear regression \n",
        "from sklearn import datasets,linear_model,metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "boston= datasets.load_boston()\n",
        "X=boston.data # x is a array \n",
        "y=boston.target # y is a array\n",
        "plt.scatter(X.T[0],y) # tracer la premiere colonne de X en fonction de y \n",
        "plt.show()\n",
        "reg=linear_model.LinearRegression()\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2)\n",
        "reg.fit(X_train,y_train)\n",
        "y_pred=reg.predict(X_test)\n",
        "score=metrics.r2_score(y_test,y_pred)\n",
        "print(score)\n",
        "print(reg.coef_) # y_i=la somme a_j x_ij sont les coeficients de regression dans ce cas on a 13 dimention donc reg.coef est de la taille de 13\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H55HotLugaQX"
      },
      "source": [
        "# Kmeans approche \n",
        "from sklearn import datasets,linear_model,metrics\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import scale\n",
        "bc= datasets.load_breast_cancer()\n",
        "X=scale(bc.data) # il y a une grande différence entre les features chacun de l'ordre de 100 autre de l'ordre de 0.01 donc on doit les scaler \n",
        "y=bc.target\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2)\n",
        "kmn=KMeans(n_clusters=2 , random_state=0)\n",
        "kmn.fit(X_train)\n",
        "y_pred=kmn.predict(X_test)\n",
        "labels=kmn.labels_\n",
        "print(labels)\n",
        "print(y_pred)\n",
        "print(metrics.accuracy_score(y_test,y_pred))\n",
        "print(y_test,y_pred)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}