{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test technique EL HANINE Nadia.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNV36Sx/mLAcDLe315SLwVm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nadia-data/nadia-data/blob/main/Test_technique_EL_HANINE_Nadia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPUFQ98h6MQO"
      },
      "source": [
        "### load and describe the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbxUV_7G6JZn"
      },
      "source": [
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "data_train=pd.read_csv('hour.csv') # reading our training data\n",
        "data_train.head()# visualizing the first five rows of our data "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04BRsHpCSi1Z"
      },
      "source": [
        "data_train.shape # checking Shape of the data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7Naxe9SSjCR"
      },
      "source": [
        " data_train.describe() # seeing statistics of our data "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSqLJCjHVgfa"
      },
      "source": [
        "data_train.isnull().sum() # checking missing values in our data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7eJ0UKpVyZr"
      },
      "source": [
        "data_train.info()  # checking missing values in our data and the columns type of the data "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9K1TbLIYQKU"
      },
      "source": [
        "data_train.insert(4,\"day\", pd.DatetimeIndex(data_train['dteday']).day, allow_duplicates=False) # add the day to our data from the date "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igVeFxtTYb7o"
      },
      "source": [
        "data_train.drop(['dteday','instant'], axis = 1, inplace = True)# get rid of columns that are not necessary for our prediction\n",
        "data_train.head() #visualize our data again to check if the day has been added and the columns has been removed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s218Rk3G6epR"
      },
      "source": [
        "#make graphic\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VKbH1ZmrcwL"
      },
      "source": [
        "data_graphic=data_train.copy() #taking a copy of the data to build useful graphs\n",
        "data_graphic.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybHOEYPvspJJ"
      },
      "source": [
        "data_graphic['season'] = data_graphic.season.map({1:'Winter', 2:'Spring', 3:'Summer', 4:'Fall'}) #add the name of each season \n",
        "data_graphic['weathersit'] =data_graphic.weathersit.map({1:'Clear', 2:'Mist', 3:'Light rain', 4:'Heavy rain'})#add the name for each weather "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nIFprDNvvkd"
      },
      "source": [
        "data_graphic.head() # "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kginjZ1wzn0A"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (18,9))\n",
        "sns.boxplot(x = 'season', y = 'cnt', data = data_graphic, ax = ax1,)#Plot the demand according to season.\n",
        "sns.boxplot(x = 'weathersit', y = 'cnt', data = data_graphic, ax = ax2)#Plot the demand according to weather."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEMDLMG20axY"
      },
      "source": [
        "On remarque que la demande est élevée en été et en printemps ce qui est normale à cause du climat et de la disponibilité des consommateurs ,de même pour la demande en temps clair ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKOIj6qC0eEF"
      },
      "source": [
        "sns.catplot(x = 'hr', y = 'cnt', data = data_graphic, kind = 'box', aspect = 3) #Plot the demand according to the hour of the day"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9GVxyX8BJDk"
      },
      "source": [
        "La valeur médiane est relativement plus élevée à 7h-8h et à 17h-18h. Cela peut être attribué aux utilisateurs réguliers des écoles et des bureaux à ces heures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVzudlFiC3_q"
      },
      "source": [
        "data_graphic['mnth'] = data_graphic.mnth.map({1:'January', 2:'February', 3:'March', 4:'April',5:'May',6:'June',7:'July',8:'August',9:'September',10:'October',11:'November',12:'December'}) # add the names of the months\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.catplot(x = 'mnth', y = 'cnt', data = data_graphic, kind = 'box', aspect = 3) #Plot the demand according to the month"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiaWttg1HP2y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQXoJElcF-V0"
      },
      "source": [
        "Il est évident que les gens ont tendance à ne pas louer des vélos pendant  saison d'hiver, car il n'est pas vraiment propice de faire du vélo à cette saison, c'est pourquoi les mois de janvier, février ont une demande relativement plus basse de vélos.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jNm5ZwBGcVD"
      },
      "source": [
        "#holiday\n",
        "sns.factorplot(x='holiday',data=data_graphic,kind='count',size=5,aspect=1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4W3or33P3NK"
      },
      "source": [
        "La plupart des points aberrants proviennent principalement des jours qui ne sont pas du vacances.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-LY_LTaP9LB"
      },
      "source": [
        "#working days\n",
        "sns.factorplot(x='workingday',data=data_graphic,kind='count',size=5,aspect=1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg-ygrTz60EJ"
      },
      "source": [
        "La plupart des points aberrants proviennent principalement des jours de travail.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzHr7cWWQbNZ"
      },
      "source": [
        "#build models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfjKRxmpSHDu"
      },
      "source": [
        "#defining our input and output\n",
        "X = data_train.drop('cnt',axis=1)\n",
        "y = data_train['cnt']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsZTOhkiXPU5"
      },
      "source": [
        "#display the scores of the mutual information to get rid of columns that will have no impact on the prediction\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "def make_mi_scores(X, y, discrete_features):\n",
        "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n",
        "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
        "    mi_scores = mi_scores.sort_values(ascending=False)\n",
        "    return mi_scores\n",
        "\n",
        "\n",
        "discrete_features = X.dtypes == int\n",
        "mi_scores = make_mi_scores(X, y, discrete_features)\n",
        "\n",
        "def plot_mi_scores(scores):\n",
        "    scores = scores.sort_values(ascending=True)\n",
        "    width = np.arange(len(scores))\n",
        "    ticks = list(scores.index)\n",
        "    plt.barh(width, scores)\n",
        "    plt.yticks(width, ticks)\n",
        "    plt.title(\"Scores de l'information mutuelles\")\n",
        "\n",
        "\n",
        "plt.figure(dpi=100, figsize=(8, 5))\n",
        "plot_mi_scores(mi_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nco2_-bgZP_D"
      },
      "source": [
        "\"casual\" et \"registred\" ne sont pas non plus pris en compte car il s'agit de variables de fuite par nature et elles doivent être abandonnées lors de la construction du modèle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC-0n8L1ZZY3"
      },
      "source": [
        "X.drop(['casual','registered'], axis = 1, inplace = True)# get rid of columns that are not necessary for our prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LFFT1OHbDcD"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 0)#separate our data on training and testing data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ar-JKQ1Fx4V0"
      },
      "source": [
        "#linear regression \n",
        "from sklearn.linear_model import LinearRegression\n",
        "# model fitting\n",
        "lr_reg = LinearRegression()\n",
        "lr_reg.fit(X_train, y_train)\n",
        "#make predection\n",
        "y_pred_ln = lr_reg.predict(X_test)\n",
        "# checking the rmsle and the r2_score\n",
        "print('r2_score:',r2_score(y_test,y_pred_ln))\n",
        "print('rmsle:',mean_squared_log_error(y_test,y_pred_ln))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_JDtAI0bOpb"
      },
      "source": [
        "#AdaBoostRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_log_error\n",
        "#fitting model AAdaBoostRegressor\n",
        "abr = AdaBoostRegressor(random_state=42)\n",
        "abr.fit( X_train , y_train )\n",
        "y_pred= abr.predict(X_test)\n",
        "# checking the rmsle and the r2_score\n",
        "print('rmsle:',mean_squared_log_error(y_test,y_pred))\n",
        "print('r2_score:',r2_score(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0p65n7m1vYy2"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# model fitting\n",
        "model_rf = RandomForestRegressor(random_state=42)\n",
        "model_rf.fit( X_train , y_train )\n",
        "# Prediction\n",
        "y_pred = model_rf.predict(X_test)\n",
        "# checking the rmsle and the r2_score\n",
        "print('rmsle:',mean_squared_log_error(y_test,y_pred))\n",
        "print('r2_score:',r2_score(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0FMAeLDek5L"
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "xgb_reg = XGBRegressor(n_estimators = 1000)\n",
        "xgb_reg.fit(X_train, y_train)\n",
        "y_pred_xg = xgb_reg.predict(X_test)\n",
        "\n",
        "# checking the rmsle and the r2_score\n",
        "print('rmsle:',mean_squared_log_error(y_test,y_pred_xg))\n",
        "print('r2_score:',r2_score(y_test,y_pred_xg))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRWnX-ug2Pws"
      },
      "source": [
        "#KNeighborsRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "model_knn = KNeighborsRegressor()\n",
        "#fitting our model\n",
        "model_knn.fit( X_train , y_train )\n",
        "#prediction\n",
        "y_pred_knn = model_knn.predict(X_test)\n",
        "# checking the rmsle and the r2_score\n",
        "print('rmsle:',mean_squared_log_error(y_test,y_pred_knn))\n",
        "print('r2_score:',r2_score(y_test,y_pred_knn))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdvRrqWb86RH"
      },
      "source": [
        "Notez que les modèles : régression linéaire, Xgboost ne sont pas bons pour notre prédiction. Le problème est que ces modèles prédisent des valeurs négatives pour la cible, ce qui n'est pas possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9ZdZZtl9UAe"
      },
      "source": [
        "pour les trois modèls qu'ils reste (KNeighborsRegressor,AdaBoostRegressor,RandomForestRegressor) on remarque que le RandomForestRegressor donne le plus petit rmsle et le meilleur r2_score .pour cela  je l'utiliserai pour faire des prédictions. mais cette fois avec une optimisation des parametrs \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXCzFODc-nDR"
      },
      "source": [
        "# parametrs optimization\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=5, random_state=42,shuffle=True)\n",
        "\n",
        "params_dict = {'n_estimators':[100, 200, 300, 1000],'n_jobs':[-1],'max_features':[\"auto\",'sqrt','log2']}\n",
        "rf_reg = GridSearchCV(estimator= model_rf,param_grid = params_dict,scoring = 'neg_mean_squared_log_error',cv = kfold)\n",
        "rf_reg.fit(X_train,y_train)\n",
        "# checking the best parameter\n",
        "rf_reg.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKAg0kKRIfKC"
      },
      "source": [
        "#RandomForestRegressor with obtimized parametrs\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# model fitting\n",
        "model_rf = RandomForestRegressor(max_features = 'auto', n_estimators= 400, n_jobs= -1,random_state=42)\n",
        "model_rf.fit( X_train , y_train )\n",
        "# Prediction\n",
        "y_pred = model_rf.predict(X_test)\n",
        "# checking the rmsle and the r2_score\n",
        "print('rmsle:',mean_squared_log_error(y_test,y_pred))\n",
        "print('r2_score:',r2_score(y_test,y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wtIvuyKI5tQ"
      },
      "source": [
        "l'obtimisation des parametres n'a pas impacté le score méme si elle a pris assez du temps pour excuter le programme"
      ]
    }
  ]
}